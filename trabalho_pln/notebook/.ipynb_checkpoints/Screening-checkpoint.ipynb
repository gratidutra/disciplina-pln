{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0089c1b-f60a-4c23-a875-532020dcbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "#!pip install scispacy\n",
    "#!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bionlp13cg_md-0.5.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09350b2-8424-4068-992e-b90c028ded47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc5dbdd-3ce2-4e63-a99e-4c3b2711726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_references_and_save(folder_path, output_folder, keywords=None):\n",
    "    if keywords is None:\n",
    "        keywords = [\"# References\", \"# Reference\", \"# Bibliography\", \"## References\", \"## Reference\", \"## Bibliography\" ]\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    md_files = [f for f in os.listdir(folder_path) if f.endswith(\".md\")]\n",
    "\n",
    "    for filename in tqdm(md_files, desc=\"Processing files\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        pattern = '|'.join(re.escape(k) for k in keywords)\n",
    "        match = re.search(f\"({pattern})\", content, re.IGNORECASE)\n",
    "        if match:\n",
    "            new_content = content[:match.start()].rstrip()\n",
    "            # Save the new content to the output folder\n",
    "            new_file_path = os.path.join(output_folder, filename)\n",
    "            with open(new_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(new_content)\n",
    "        else:\n",
    "            # Copy the file if no references section was found\n",
    "            shutil.copy(file_path, os.path.join(output_folder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43abb65f-38b0-4fdf-a9b0-3d09c381db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(model, document_text, document_name):\n",
    "    nlp = model.load()\n",
    "\n",
    "    if \"entity_ruler\" in nlp.pipe_names:\n",
    "        ruler = nlp.get_pipe(\"entity_ruler\")\n",
    "        ruler.clear()\n",
    "    else:\n",
    "        ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "    custom_labels = {\"MUTATION\", \"MEASURE\", \"METHOD\", 'GENE_OR_GENE_PRODUCT'}\n",
    "\n",
    "    patterns = [\n",
    "        # MUTATION\n",
    "        {\n",
    "            \"label\": \"MUTATION\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^(Œî|[A-Z])[0-9]+(?:[A-Za-z]*|del|ins|dup|fs|X)$\"}}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"MUTATION\",\n",
    "            \"pattern\": [\n",
    "                {\"LOWER\": \"mutation\"},\n",
    "                {\"TEXT\": {\"REGEX\": r\"^(Œî|[A-Z])[0-9]+(?:[A-Za-z]*|del|ins|dup|fs|X)$\"}}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"MUTATION\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^p\\.[A-Z][a-z]{2}[0-9]+(?:[A-Za-z]*|del|ins|dup)\"}}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"MUTATION\",\n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": {\"REGEX\": r\"^c\\.[0-9]+(?:_[0-9]+)?(?:del|ins|dup)[A-Z]*\"}}\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        # Measure - DSC\n",
    "        {\n",
    "            \"label\": \"MEASURE\", \n",
    "            \"pattern\": [\n",
    "                {\"LOWER\": \"differential\"},\n",
    "                {\"LOWER\": \"scanning\"},\n",
    "                {\"LOWER\": \"calorimetry\"},\n",
    "                {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"dsc\", \"OP\": \"?\"},\n",
    "                {\"TEXT\": \")\", \"OP\": \"?\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"MEASURE\", \n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"dsc\"},\n",
    "                {\"TEXT\": \")\", \"OP\": \"?\"}\n",
    "            ]\n",
    "        },\n",
    "\n",
    "        # METHOD - CD\n",
    "        {\n",
    "            \"label\": \"MEASURE\", \n",
    "            \"pattern\": [\n",
    "                {\"LOWER\": \"circular\"},\n",
    "                {\"LOWER\": \"dichroism\"},\n",
    "                {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"cd\", \"OP\": \"?\"},\n",
    "                {\"TEXT\": \")\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"spectroscopy\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"MEASURE\", \n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"cd\"},\n",
    "                {\"TEXT\": \")\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"spectroscopy\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"MEASURE\", \n",
    "            \"pattern\": [\n",
    "                {\"TEXT\": \"(\", \"OP\": \"?\"},\n",
    "                {\"LOWER\": \"cd\"},\n",
    "                {\"TEXT\": \")\", \"OP\": \"?\"}\n",
    "            ]\n",
    "        },\n",
    "                # METHOD - Agentes desnaturantes e ensaios\n",
    "        {\n",
    "            \"label\": \"METHOD\",\n",
    "            \"pattern\": [{\"LOWER\": \"urea\"}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"METHOD\",\n",
    "            \"pattern\": [{\"LOWER\": \"gdn\"}, {\"LOWER\": \"hcl\"}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"METHOD\",\n",
    "            \"pattern\": [{\"LOWER\": \"guanidine\"}, {\"LOWER\": \"hydrochloride\"}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"METHOD\",\n",
    "            \"pattern\": [{\"LOWER\": \"thermal\"}, {\"LOWER\": \"shift\"}, {\"LOWER\": \"assay\"}]\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"METHOD\",\n",
    "            \"pattern\": [{\"LOWER\": \"tsa\"}]\n",
    "        }\n",
    "\n",
    "    ]\n",
    "\n",
    "    # Adiciona os padr√µes ao ruler\n",
    "    ruler.add_patterns(patterns)\n",
    "\n",
    "    # Processamento\n",
    "    doc = nlp(document_text)\n",
    "\n",
    "    # Coleta de entidades\n",
    "    seen = set()\n",
    "    entity = []\n",
    "    label = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in custom_labels and ent.text not in seen:\n",
    "            entity.append(ent.text)\n",
    "            label.append(ent.label_)\n",
    "            seen.add(ent.text)\n",
    "\n",
    "    # Regex para termos termodin√¢micos\n",
    "    #delta_pattern = re.compile(r'''\n",
    "    #    (?P<symbol>Œî|delta|Delta)\\s*(?P<variable>[GT])|ùö´\\s*(?P<variable2>[GT]?) ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† \n",
    "    #    (?:\\s*[:=~]\\s*(?P<value>[-\\d.]+)\\s*(?P<unit>kcal/mol|kJ/mol|¬∞C|K)?)?\n",
    "    #    (?:.*?(Fig(?:ure)?\\s*[\\dS]+)?)?\n",
    "    #''', flags=re.IGNORECASE | re.VERBOSE)\n",
    "\n",
    "    #delta_matches = []\n",
    "    #for match in delta_pattern.finditer(document_text):\n",
    "    #    termo = match.group(\"variable\") or match.group(\"variable2\")\n",
    "    #    if termo:\n",
    "    #        termo = termo.upper()\n",
    "    #        valor = match.group(\"value\") or \"\"\n",
    "    #        unidade = match.group(\"unit\") or \"\"\n",
    "    #        delta_matches.append({\n",
    "    #            \"termo\": f\"Œî{termo}\",\n",
    "    #            \"valor\": valor,\n",
    "    #            \"unidade\": unidade\n",
    "    #        })\n",
    "\n",
    "    return {\n",
    "        \"pmid\": document_name,\n",
    "        \"entity\": entity,\n",
    "        \"label\": label,\n",
    "        #\"termos_termodinamicos\": delta_matches,\n",
    "        #\"tem_termo_termodinamico\": \"Sim\" if delta_matches else \"N√£o\"\n",
    "    }\n",
    "\n",
    "class SpacyModel:\n",
    "    def load(self):\n",
    "        return spacy.load(\"en_ner_bionlp13cg_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03685264-3be5-4e5e-902e-f53ebc5c76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"../data/md\"\n",
    "output_folder = \"../data/cleaned_md\"\n",
    "#remove_references_and_save(source_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a9bb0-5f68-4878-a2f5-7fbab80f8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando arquivos:   0%|                               | 0/6 [00:00<?, ?it/s]/home/grati/miniconda3/envs/pln/lib/python3.12/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n",
      "Processando arquivos:  17%|‚ñà‚ñà‚ñà‚ñä                   | 1/6 [00:39<03:15, 39.13s/it]"
     ]
    }
   ],
   "source": [
    "# Caminho da pasta onde est√£o os arquivos .md\n",
    "caminho_pasta = \"../data/md_cleaned\"\n",
    "\n",
    "# Instanciar o modelo spaCy\n",
    "model = SpacyModel()\n",
    "\n",
    "# Lista para armazenar os resultados\n",
    "todos_resultados = []\n",
    "\n",
    "# Listar arquivos .md\n",
    "arquivos_md = [f for f in os.listdir(caminho_pasta) if f.endswith(\".md\")]\n",
    "\n",
    "# Iterar com barra de progresso\n",
    "for nome_arquivo in tqdm(arquivos_md, desc=\"Processando arquivos\"):\n",
    "    caminho_completo = os.path.join(caminho_pasta, nome_arquivo)\n",
    "    with open(caminho_completo, \"r\", encoding=\"utf-8\") as f:\n",
    "        document_text = f.read()\n",
    "\n",
    "    # Aplicar a fun√ß√£o\n",
    "    resultado = extract_entities(model, document_text, nome_arquivo)\n",
    "\n",
    "    # Adiciona resultados linha por linha\n",
    "    for ent, label in zip(resultado[\"entity\"], resultado[\"label\"]):\n",
    "        todos_resultados.append({\n",
    "            \"pmid\": resultado[\"pmid\"],\n",
    "            \"entity\": ent,\n",
    "            \"label\": label,\n",
    "            #\"tem_termo_termodinamico\": resultado[\"tem_termo_termodinamico\"]\n",
    "        })\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(todos_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e48da-bc11-4321-aed7-b09dcd8b8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(['pmid', 'label'])['entity'].apply(list).unstack(fill_value=[]).reset_index()\n",
    "\n",
    "# Adiciona os campos extras (termodin√¢mica)\n",
    "df_termos = df[['pmid', 'tem_termo_termodinamico']].drop_duplicates()\n",
    "\n",
    "# Junta tudo\n",
    "df_final = pd.merge(df_grouped, df_termos, on='pmid', how='left')\n",
    "\n",
    "def calc_term_probability(row):\n",
    "    score = 0\n",
    "    if row['METODH']:        \n",
    "        score += 0.5\n",
    "    if row['MUTATION']:        \n",
    "        score += 0.166\n",
    "    if row['GENE']:              \n",
    "        score += 0.166\n",
    "    if row['MEASURE']:     \n",
    "        score += 0.166\n",
    "\n",
    "    return round(score, 2)\n",
    "\n",
    "df_final['probability'] = df_final.apply(calc_term_probability, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04035ea0-2803-484b-a838-76834a2ccd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['bin'] = (df_final['probability'] > 0.5).astype(int)\n",
    "\n",
    "df_final['pmid'] = df_final['pmid'].str.replace('.md', '', regex=False)\n",
    "\n",
    "df_final.to_csv('../data/model/papers_screened.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cba709-6135-4ec3-9bbb-23fbf5889647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.query('pmid == 31605637')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03bf3c5-03bf-41ac-b909-bb8c235c899a",
   "metadata": {},
   "source": [
    "### Fisrt version joined methodologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0ac37-8168-4fc5-828e-51a8f638e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "official_data = pd.read_excel('../data/model/oficial_data.xlsx')\n",
    "\n",
    "official_data['pmid'] = official_data['pmid'].astype(int)\n",
    "\n",
    "df_final['pmid'] = df_final['pmid'].astype(int)\n",
    "\n",
    "official_data.merge(df_final[['pmid', 'bin']], on='pmid', how='left').to_excel('../data/model/official_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b02381-ecc3-4baa-a0d4-463c58854956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
